# 索引

## 创建索引

对 x 表的 a 列添加普通索引，对b列添加唯一索引：

    (root@localhost) [test]> desc x;
    +-------+---------+------+-----+---------+-------+
    | Field | Type    | Null | Key | Default | Extra |
    +-------+---------+------+-----+---------+-------+
    | a     | int(11) | YES  |     | NULL    |       |
    | b     | int(11) | YES  |     | NULL    |       |
    +-------+---------+------+-----+---------+-------+
    2 rows in set (0.00 sec)

    (root@localhost) [test]> show create table x\G
    *************************** 1. row ***************************
          Table: x
    Create Table: CREATE TABLE `x` (
      `a` int(11) DEFAULT NULL,
      `b` int(11) DEFAULT NULL
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    1 row in set (0.00 sec)

    (root@localhost) [test]> alter table x add unique index idx_b(b);
    Query OK, 0 rows affected (0.04 sec)
    Records: 0  Duplicates: 0  Warnings: 0

    (root@localhost) [test]> alter table x add index idx_a(a);
    Query OK, 0 rows affected (0.03 sec)
    Records: 0  Duplicates: 0  Warnings: 0

删除索引：

    (root@localhost) [test]> alter table x drop index idx_b;
    Query OK, 0 rows affected (0.01 sec)
    Records: 0  Duplicates: 0  Warnings: 0

    (root@localhost) [test]> alter table x drop index idx_a;
    Query OK, 0 rows affected (0.01 sec)
    Records: 0  Duplicates: 0  Warnings: 0

但是在线上对数据量大的表加索引就不太一样，需要调大一个参数否则创建索引可能会失败

5.6 以前的版本中创建索引的时候会加一把读锁，加上读锁之后创建索引的这段时间，这段时间中 select 操作是可以执行的，但是 insert 操作则会阻塞

5.6 开始原生支持在线的索引添加，创建索引的过程中表依然是可读可写的

## 一个比较重要的参数 **innodb_online_alter_log_max_size**

这个参数表示 alter table 加索引的过程中对这张表做操作会先记录到 alter_table 的日志里面，但这个日志是内存的大小是128M，如果超过这个空间的话创建索引的操作就会报错，其他的 Online DDL 操作也会报错导致失败

    (root@localhost) [test]> show variables like 'innodb%max%';
    +----------------------------------+------------+
    | Variable_name                    | Value      |
    +----------------------------------+------------+
    | innodb_adaptive_max_sleep_delay  | 150000     |
    | innodb_change_buffer_max_size    | 25         |
    | innodb_compression_pad_pct_max   | 50         |
    | innodb_file_format_max           | Barracuda  |
    | innodb_ft_max_token_size         | 84         |
    | innodb_io_capacity_max           | 2000       |
    | innodb_max_dirty_pages_pct       | 75.000000  |
    | innodb_max_dirty_pages_pct_lwm   | 0.000000   |
    | innodb_max_purge_lag             | 0          |
    | innodb_max_purge_lag_delay       | 0          |
    | innodb_max_undo_log_size         | 1073741824 |
    | innodb_online_alter_log_max_size | 134217728  | <-- 相关参数
    +----------------------------------+------------+
    12 rows in set (0.00 sec)

所以建议把这个值调大点

    (root@localhost) [test]> set global innodb_online_alter_log_max_size=512*1024*1024;
    Query OK, 0 rows affected (0.00 sec)

加入my.cnf，根据服务器配置调整

    # innodb
    innodb_buffer_pool_size = 1G
    innodb_log_file_size = 128M
    innodb_online_alter_log_max_size = 256M

## 在线索引添加遇到的问题--主从延时

比如在主库上的 orders 表上执行了 DDL 操作，比如添加索引用了 5 分钟，那么在从库上面也会去执行这样一个 DDL 操作也需要 5 分钟这样的一个时间，那么就会产生一个5分钟的延时（等 master 上的执行完了后，slave 才开始那个操作）

所以真正在线上会很少直接用 alter table add indexl，alter table add column 这样的方式去执行DDL操作的，即使在 5.7 本版中越来越多的操作对读写都是不阻塞的，但是存在的最大的一个问题就是延时

### Percona Toolkit 工具包

doc https://www.percona.com/doc/percona-toolkit/LATEST/index.html

里面除了 pt-online-schema-change 其他的用处不大

下载

    wget https://github.com/percona/percona-toolkit/archive/refs/tags/v3.3.1.tar.gz

加入环境变量

    $ vim ~/.zshrc

    PATH=~/dl/percona-toolkit-3.3.1/bin:$PATH:$HOME/bin

    $ zsh

#### pt-online-schema-change

这个工具可以在线的用来创建索引或者是DDL，好处是延时非常小，这个工具并不是直接去创建的，而是通过触发器的机制去慢慢的加，有很多参数可以用来控制延时

使用方法：(--alter: alter table "需要执行的操作" D=数据库名 t=表名)

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a
    Operation, tries, wait: <--这里只是显示了步骤
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Exiting without altering `test`.`a` because neither --dry-run nor --execute was specified.  Please read the tool's documentation carefully before using this tool.

    # root @ iZbp16g9pt4wd4rs0iwqrfZ in ~/dl/percona-toolkit-3.3.1/bin [13:26:14] C:1
    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a --execute  <--真正执行需要加上--execute參數
    No slaves found.  See --recursion-method if host iZbp16g9pt4wd4rs0iwqrfZ has slaves.
    Not checking slave lag because no slaves were found and --check-slave-lag was not specified.
    Operation, tries, wait:
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Altering `test`.`a`...
    Creating new table...
    Created new table test._a_new OK.
    Altering new table...
    Altered `test`.`_a_new` OK.
    2022-01-15T13:26:19 Creating triggers...
    2022-01-15T13:26:19 Created triggers OK.
    2022-01-15T13:26:19 Copying approximately 1 rows...
    2022-01-15T13:26:19 Copied rows OK.
    2022-01-15T13:26:19 Analyzing new table...
    2022-01-15T13:26:19 Swapping tables...
    2022-01-15T13:26:19 Swapped original and new tables OK.
    2022-01-15T13:26:19 Dropping old table...
    2022-01-15T13:26:19 Dropped old table `test`.`_a_old` OK.
    2022-01-15T13:26:19 Dropping triggers...
    2022-01-15T13:26:19 Dropped triggers OK.
    Successfully altered `test`.`a`.

    -- 创建索引
    $ pt-online-schema-change --alter "add index idx_a(a)" D=test,t=a --execute
    No slaves found.  See --recursion-method if host iZbp16g9pt4wd4rs0iwqrfZ has slaves.
    Not checking slave lag because no slaves were found and --check-slave-lag was not specified.
    Operation, tries, wait:
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Altering `test`.`a`...
    Creating new table...
    Created new table test._a_new OK.
    Altering new table...
    Altered `test`.`_a_new` OK.
    2022-01-15T13:33:34 Creating triggers...
    2022-01-15T13:33:34 Created triggers OK.
    2022-01-15T13:33:34 Copying approximately 1 rows...
    2022-01-15T13:33:34 Copied rows OK.
    2022-01-15T13:33:34 Analyzing new table...
    2022-01-15T13:33:34 Swapping tables...
    2022-01-15T13:33:34 Swapped original and new tables OK.
    2022-01-15T13:33:34 Dropping old table...
    2022-01-15T13:33:34 Dropped old table `test`.`_a_old` OK.
    2022-01-15T13:33:34 Dropping triggers...
    2022-01-15T13:33:34 Dropped triggers OK.
    Successfully altered `test`.`a`.

    (root@localhost) [test]> show create table a\G
    *************************** 1. row ***************************
          Table: a
    Create Table: CREATE TABLE `a` (
      `z` int(11) NOT NULL,
      `a` varchar(512) DEFAULT NULL,
      PRIMARY KEY (`z`),
      KEY `idx_a` (`a`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    1 row in set (0.00 sec)
    这个工具在线上数据量大的情况下，创建索引不是一下子创建完的是慢慢创建的

注意这里在my.cnf中配置了用户名密码，所以使用这个工具没有带上用户名密码，如果没有配置用户名密码，需要在工具的参数里带上

查看工具的各项参数：

    $ pt-online-schema-change --help

#### 实现原理

这个工具还是非常有技术含量的

简单来说的话会根据原表（比如 s 表）先创建一张 _tmp_s 的临时表

接着会去原表上创建 insert、update、delete 的触发器，如果在执行过程中新产生的数据就会触发过去，触发器触发过去的是增量数据

但是老的数据则先需要把全量数据给拉过去，全量数据拉过去的时候是通过 insert tmp_s select from s(带 limit，可调)一批一批过去的

那么可以注意到一个问题，怎么保证全量数据先过去还是增量数据先过去，比如说有150万行的原数据还没同步过去增量数据就先过去了，所以这个工具里还有很多细节可以探讨

看实现原理：

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a --dry-run <-- dry-run 表示只运行不实际导数据
    Operation, tries, wait:
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Starting a dry run.  `test`.`a` will not be altered.  Specify --execute instead of --dry-run to alter the table.
    Creating new table...
    Created new table test._a_new OK. <--创建了临时表
    Altering new table...
    Altered `test`.`_a_new` OK.
    Not creating triggers because this is a dry run. <--创建触发器
    Not copying rows because this is a dry run. <--拷贝数据
    Not swapping tables because this is a dry run. <--重命名
    Not dropping old table because this is a dry run. <--删除原来的表
    Not dropping triggers because this is a dry run. <--删除触发器
    2022-01-15T14:04:39 Dropping new table...
    2022-01-15T14:04:39 Dropped new table OK.
    Dry run complete.  `test`.`a` was not altered.

通过 general_log 查看执行过程：

    (root@localhost) [(none)]> set global log_output = 'table'; -- 日志存到表里
    Query OK, 0 rows affected (0.00 sec)

    (root@localhost) [(none)]> use mysql;
    Database changed
    (root@localhost) [mysql]> truncate table general_log; -- 清一下日志的旧数据
    Query OK, 0 rows affected (0.01 sec)

    (root@localhost) [mysql]> set global general_log = 1; -- 打开general_log
    Query OK, 0 rows affected (0.01 sec)

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a --execut --执行工具命令

    (root@localhost) [mysql]> set global general_log = 0; -- 关闭general_log
    Query OK, 0 rows affected (0.00 sec)

    (root@localhost) [mysql]> select argument from general_log where thread_id = 24;
    +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    | argument

                                              |
    +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    | root@localhost on test using Socket

                                              |
    | SHOW VARIABLES LIKE 'innodb\_lock_wait_timeout'

                                              |
    | SET SESSION innodb_lock_wait_timeout=1

                                              |
    | SHOW VARIABLES LIKE 'lock\_wait_timeout'

                                              |
    | SET SESSION lock_wait_timeout=60

                                              |
    | SHOW VARIABLES LIKE 'wait\_timeout'

                                              |
    | SET SESSION wait_timeout=10000

                                              |
    | SELECT @@SQL_MODE

                                              |
    | SET @@SQL_QUOTE_SHOW_CREATE = 1/*!40101, @@SQL_MODE='NO_AUTO_VALUE_ON_ZERO,ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'*/
                                              |
    | SELECT VERSION()

                                              |
    | SHOW VARIABLES LIKE 'character_set_server'

                                              |
    | SELECT @@server_id /*!50038 , @@hostname*/

                                              |
    | SHOW VARIABLES LIKE 'wsrep_on'

                                              |
    | SHOW VARIABLES LIKE 'version%'

                                              |
    | SHOW ENGINES

                                              |
    | SHOW VARIABLES LIKE 'innodb_version'

                                              |
    | SHOW VARIABLES LIKE 'innodb_stats_persistent'

                                              |
    | SELECT @@SERVER_ID

                                              |
    | SHOW GRANTS FOR CURRENT_USER()

                                              |
    | SHOW FULL PROCESSLIST

                                              |
    | SHOW SLAVE HOSTS

                                              |
    | SHOW GLOBAL STATUS LIKE 'Threads_running'

                                              |
    | SHOW GLOBAL STATUS LIKE 'Threads_running'

                                              |
    | SELECT CONCAT(@@hostname, @@port)

                                              |
    | SHOW TABLES FROM `test` LIKE 'a'

                                              |
    | SELECT VERSION()

                                              |
    | SHOW TRIGGERS FROM `test` LIKE 'a'

                                              |
    | /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */

                                              | <--上面是获取表对应的一些信息
    | USE `test`

                                              |
    | SHOW CREATE TABLE `test`.`a`

                                              | <--看表结构
    | /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */

                                              |
    | EXPLAIN SELECT * FROM `test`.`a` WHERE 1=1

                                              | <--explain表
    | SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema='test' AND referenced_table_name='a'  
                                              | <--获取表的列信息
    | SHOW VARIABLES LIKE 'version%'

                                              |
    | SHOW ENGINES

                                              |
    | SHOW VARIABLES LIKE 'innodb_version'

                                              |
    | SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema='test' AND referenced_table_name='a'  
                                              |
    | SHOW VARIABLES LIKE 'wsrep_on'

                                              |
    | /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */

                                              |
    | USE `test`

                                              |
    | SHOW CREATE TABLE `test`.`a`

                                              |
    | /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */

                                              |
    | CREATE TABLE `test`.`_a_new` (
      `z` int(11) NOT NULL,
      `a` varchar(512) DEFAULT NULL,
      PRIMARY KEY (`z`),
      KEY `idx_a` (`a`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
                                                          | <--创建新的表
    | ALTER TABLE `test`.`_a_new` CONVERT TO CHARACTER SET utf8mb4

                                              | <--执行alter table操作，因为是空的新表所以alter table操作几乎瞬间完成
    | /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */

                                              |
    | USE `test`

                                              |
    | SHOW CREATE TABLE `test`.`_a_new`

                                              |
    | /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */

                                              |
    | SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'DELETE'    AND ACTION_TIMING = 'AFTER'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'  |
    | SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'UPDATE'    AND ACTION_TIMING = 'AFTER'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'  |
    | SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'INSERT'    AND ACTION_TIMING = 'AFTER'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'  |
    | SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'DELETE'    AND ACTION_TIMING = 'BEFORE'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a' |
    | SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'UPDATE'    AND ACTION_TIMING = 'BEFORE'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a' |
    | SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'INSERT'    AND ACTION_TIMING = 'BEFORE'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a' |
    | CREATE TRIGGER `pt_osc_test_a_del` AFTER DELETE ON `test`.`a` FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR 1146 begin end; DELETE IGNORE FROM `test`.`_a_new` WHERE `test`.`_a_new`.`z` <=> OLD.`z`; END
                                              | <--创建了delete触发器，IGNORE表示忽略错误，这里加上是为了如果有外键关联会删除失败，所以要加上IGNORE；<=>可以判断NULL值和非NULL值
    | CREATE TRIGGER `pt_osc_test_a_upd` AFTER UPDATE ON `test`.`a` FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR 1146 begin end; DELETE IGNORE FROM `test`.`_a_new` WHERE !(OLD.`z` <=> NEW.`z`) AND `test`.`_a_new`.`z` <=> OLD.`z`; REPLACE INTO `test`.`_a_new` (`z`, `a`) VALUES (NEW.`z`, NEW.`a`); END                             | <--创建了replace机制的update触发器
    | CREATE TRIGGER `pt_osc_test_a_ins` AFTER INSERT ON `test`.`a` FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR 1146 begin end; REPLACE INTO `test`.`_a_new` (`z`, `a`) VALUES (NEW.`z`, NEW.`a`);END
                                              | <--创建了replace机制的insert触发器
    | EXPLAIN SELECT * FROM `test`.`a` WHERE 1=1

                                              |
    | EXPLAIN SELECT `z`, `a` FROM `test`.`a` LOCK IN SHARE MODE /*explain pt-online-schema-change 99163 copy table*/

                                              |
    | INSERT LOW_PRIORITY IGNORE INTO `test`.`_a_new` (`z`, `a`) SELECT `z`, `a` FROM `test`.`a` LOCK IN SHARE MODE /*pt-online-schema-change 99163 copy table*/
                                              | <--全量导入，LOCK IN SHARE MODE表示锁定的读；LOW_PRIORITY表示没有其他读取的时候才执行这个操作就是降低优先级；IGNORE忽略出错信息，增量数据先执行再执行旧数据就重复了，IGNORE就可以忽略执行顺序不同而导致的出错信息
    | SHOW WARNINGS

                                              |
    | SELECT @@SERVER_ID

                                              |
    | SHOW GRANTS FOR CURRENT_USER()

                                              |
    | SHOW FULL PROCESSLIST

                                              |
    | SHOW SLAVE HOSTS

                                              |
    | SHOW GLOBAL STATUS LIKE 'Threads_running'

                                              |
    | ANALYZE TABLE `test`.`_a_new` /* pt-online-schema-change */

                                              |
    | RENAME TABLE `test`.`a` TO `test`.`_a_old`, `test`.`_a_new` TO `test`.`a`

                                              |
    | DROP TABLE IF EXISTS `test`.`_a_old`

                                              |
    | DROP TRIGGER IF EXISTS `test`.`pt_osc_test_a_del`

                                              |
    | DROP TRIGGER IF EXISTS `test`.`pt_osc_test_a_upd`

                                              |
    | DROP TRIGGER IF EXISTS `test`.`pt_osc_test_a_ins`

                                              |
    | SHOW TABLES FROM `test` LIKE '\_a\_new'

                                              |
    |

                                              |
    +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    74 rows in set (0.00 sec)

用了 replace 机制（命令）就能避免全量数据后执行增量数据先执行的问题，比如说这时候 update 一条以前的旧数据但是全量的还没进来，那就无法 update，但是没有关系这里直接用 replace 把最后的数据先插进去就行了，replace 如果遇到了有旧数据就会把老数据删除，重新插入新的数据

这个工具有一个限制，就是每张表一定要有主键

这个工具延时不大的原因是相较于普通的做法是 alter 执行完了才会去从库去执行，而这个工具则把操作拆成了很多的小的操作去执行，每一个拆出来的操作都会同步到从机上去，这就是他的优点主从延时会非常小

缺点是执行时间会变很长

对 dbt3 表执行了这个命令发现 time_statistics 表没有主键所以工具执行失败，为该表添加主键解决问题：

    (root@localhost) [dbt3]> alter table time_statistics add column time_id int not null auto_increment primary key first;
    Query OK, 0 rows affected (0.07 sec)

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=dbt3,t=time_statistics --execute

对 emp 库的 employees 也执行失败，提示有外键关联，这个时候要加上参数--alter-foreign-keys-metho=rebuild_constraints，没有外键关联的不要加这个参数不然也会报错

    ......
    ......
    You did not specify --alter-foreign-keys-method, but there are foreign keys that reference the table. Please read the tool's documentation carefully.

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=emp,t=employees --alter-foreign-keys-method=rebuild_constraints --execute

### TIPS：<=> 可以判断 NULL 值和非 NULL 值，不用写 is null

    (root@localhost) [test]> select * from z;
    +------+
    | b    |
    +------+
    | NULL |
    |    1 |
    |    2 |
    |    3 |
    +------+
    4 rows in set (0.01 sec)

    (root@localhost) [test]> select * from z where b = NULL;
    Empty set (0.00 sec)

    (root@localhost) [test]> select * from z where b <=> NULL;
    +------+
    | b    |
    +------+
    | NULL |
    +------+
    1 rows in set (0.01 sec)

    (root@localhost) [test]> select * from z where b <=> 1;
    +------+
    | b    |
    +------+
    | 1    |
    +------+
    1 rows in set (0.01 sec)

## 索引组织表

* IOT 简写
* 对于主键的索引
  * 叶子节点存放了这一整行所有的数据
* 其他索引
  * 叶子节点只是存放了索引的键值和主键值
* 回表
* 16K 每页
* 高扇出

假设一张表有a、b、c、d四个列，a为主键

| PK  |     |     |     |
| --- | --- | --- | --- |
| a   | b   | c   | d   |
| ... | ... | ... | ... |
| ... | ... | ... | ... |
| ... | ... | ... | ... |

对于主键的这棵索引对应的叶子节点存放的是一整行记录，包含所有的列 "|a|b|c|d|"

对于二级索引(普通索引、唯一索引)来说的话，存放的是索引的列以及主键的列 "|b|a|"

对于非页节点不管是主键还是二级索引，存放的都是索引的列和指针 "|KEY|Point|"，指针的大小在MySQL中固定的是6字节，非叶节点不存数据

如果表没有加主键，MySQL 会自动帮你创建一个主键，但是对用户来说是不可见的

这就是索引组织表

### 计算问题

假设有张表主键值是 A 是 8 个字节的 bigint，每条记录大小是 300 字节，每个页大小默认是 16K

#### 问题1：如果说这张表 B+ 树的高度为 1，能存放多少条记录？

高度为 1 表示 root 页就是叶子页

每页存放数/每条记录大小 = 16*1024/300 ≈ 50

#### 问题2：如果说这张表 B+ 树的高度为 2，能存放多少条记录？

高度为 2 的时候

此时高度为 1 的非叶节点存放的是索引列和指针，现在索引的列是 8 个字节指针是 6 个字节，所以每一条记录是 14 个字节

16*1024/(8+6) ≈ 1000  也就是扇出了 1000 个叶子节点，那么答案就是 50\*1000 ≈ 50000 条记录

#### 问题3：如果说这张表 B+ 树的高度为 3，能存放多少条记录？

根据问题 2 的原理，那么就是 50\*1000\*1000 ≈ 5000 万条记录

如果是 4 层就再乘以 1000 ≈ 500 亿条记录

B+ 树在实际的生产过程当中不会很高，一般最高 4，5 层就差不多了

#### 意义

B+ 树的总体高度不高意味着根据索引的查询次数不多，表变大了数据变大了查询速度不会几何级的上升，哪怕 4 层 500 亿数据了也还是只要查询 4 次就行了

最差的 HDD 盘每秒能做 100 次 IO 找 3 次 = 3/100 = 0.03 秒，找 4 次也就 4/100 = 0.04 秒，如果存储介质改用 SSD 会更快(至少 100 倍)

B+ 树的好处是查询非常快，这里指查询 1 条记录或某几条记录，几千万的数据根据 join 的当然还是会慢的

### 回表概念

如果查询的条件是主键，那么只要一次就可以把数据查询完毕

但是如果查询条件不是主键索引而是其他(二级)索引，那么会先从索引组织表中先查询出其他索引对应的主键索引，然后再用主键索引查询一次，这就是回表

举个例子，下面的表中 a 是主键 b 是二级索引

    | PK  | KEY |     |     |
    | --- | --- | --- | --- |
    | a   | b   | c   | d   |
    | ... | ... | ... | ... |
    | ... | ... | ... | ... |
    | ... | ... | ... | ... |

根据主键所有查询的时候只要一次

    select where a = ?

根据二级索引查询要两次，即书签查找，也叫做回表

    select a where b = ? 
    select c,d where a = ?

所以主键查询要比二级索引查询速度快

## 堆表 -- MyISAM

* 所有的数据存放在一个堆文件里面
* 索引存在各自的索引文件里面
* 无序数据的集合叫做堆
* 堆表中主键索引或者二级索引中存放了指向堆表具体数据一个指针

## 组织索引表和堆表的优缺点

### 因为插入是不用考虑排序所以堆表的插入速度比较快

其实这个观点是不对的，虽然说数据插入到堆是无序数据组合速度很快等等这都是对的，问题是表上会没有任何索引的吗，除非建的表是没有索引的也就是所有的数据是存放在堆中的那么 insert 速度的确是很快的

所以说除非全部是堆表没有索引，那么这个条件或许成立

第二点 MySQL 每张表最好一定要有一个主键，一旦有主键了一定会对应一个索引，一旦有索引插入速度都是差不多的

### MyISAM (堆表) InnoDB (索引组织表)，哪种引擎更好

MyISAM 适合读？InnoDB 适合写？这个观点对现在的版本来说已然是错误的，从 5.7 开始任何场景下都是 InnoDB 快，MyISAM 跑多核肯定是跑不满的

索引组织表中的回表，PK 查询要比二级索引查询要快

在堆表中并没有这个问题，因为堆表的叶子节点存放的是指针不需要额外的一次查询，所以堆表是没有回表的或者认为它的回表就是去查询堆表

堆表中 PK 查询和二级索引查询的速度在同规模下速度基本是一致的

堆表的缺点是：

连续性不是很好，做主键的范围查询的时候速度没有索引组织表快，但是主键的范围查询通常来说也用得并不多

在做 DML 操作的时候维护索引代价大所有的索引都需要修改，比如主键为 1 的这条记录现在这条记录占用 100 个字节，这时候如果发生了更新变成 300 个字节了，首先堆表不能原地更新，如果不能在同一个位置更新就会在堆表中新找一块空间，然后再去更新主键 1

这时候会发现主键值为 1 的这条记录位置发生了更新，但是索引的叶子节点又都指向的是物理地址，这时候就都要更新

在索引组织表中，如果主键的值不更改的话对于非索引列的更新不需要修改其他的索引，因为二级索引里存放的是一个主键值，只要主键值不变化二级索引就不需要更新

#### 填充因子

一个页插满的时候，会留出一部分空间留给这个页中的其他记录进行更新，这个叫填充因子

MySQL 的填充因子默认是一个页大小的 1/16(1K)

    (root@localhost) [(none)]> show variables like 'innodb%fill%';
    +--------------------+-------+
    | Variable_name      | Value |
    +--------------------+-------+
    | innodb_fill_factor | 100   |
    +--------------------+-------+
    1 row in set (0.00 sec)

虽然InnoDB不会有一条记录更新了，然后所有索引都需要更新的情况