# 索引

## 创建索引

对 x 表的 a 列添加普通索引，对b列添加唯一索引：

    (root@localhost) [test]> desc x;
    +-------+---------+------+-----+---------+-------+
    | Field | Type    | Null | Key | Default | Extra |
    +-------+---------+------+-----+---------+-------+
    | a     | int(11) | YES  |     | NULL    |       |
    | b     | int(11) | YES  |     | NULL    |       |
    +-------+---------+------+-----+---------+-------+
    2 rows in set (0.00 sec)

    (root@localhost) [test]> show create table x\G
    *************************** 1. row ***************************
          Table: x
    Create Table: CREATE TABLE `x` (
      `a` int(11) DEFAULT NULL,
      `b` int(11) DEFAULT NULL
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    1 row in set (0.00 sec)

    (root@localhost) [test]> alter table x add unique index idx_b(b);
    Query OK, 0 rows affected (0.04 sec)
    Records: 0  Duplicates: 0  Warnings: 0

    (root@localhost) [test]> alter table x add index idx_a(a);
    Query OK, 0 rows affected (0.03 sec)
    Records: 0  Duplicates: 0  Warnings: 0

删除索引：

    (root@localhost) [test]> alter table x drop index idx_b;
    Query OK, 0 rows affected (0.01 sec)
    Records: 0  Duplicates: 0  Warnings: 0

    (root@localhost) [test]> alter table x drop index idx_a;
    Query OK, 0 rows affected (0.01 sec)
    Records: 0  Duplicates: 0  Warnings: 0

但是在线上对数据量大的表加索引就不太一样，需要调大一个参数否则创建索引可能会失败

5.6 以前的版本中创建索引的时候会加一把读锁，加上读锁之后创建索引的这段时间，这段时间中 select 操作是可以执行的，但是 insert 操作则会阻塞

5.6 开始原生支持在线的索引添加，创建索引的过程中表依然是可读可写的

### 一个比较重要的参数 **innodb_online_alter_log_max_size**

这个参数表示 alter table 加索引的过程中对这张表做操作会先记录到 alter_table 的日志里面，但这个日志是内存的大小是 128M，如果超过这个空间的话创建索引的操作就会报错，其他的 Online DDL 操作也会报错导致失败

    (root@localhost) [test]> show variables like 'innodb%max%';
    +----------------------------------+------------+
    | Variable_name                    | Value      |
    +----------------------------------+------------+
    | innodb_adaptive_max_sleep_delay  | 150000     |
    | ...                              | ...        |
    | innodb_online_alter_log_max_size | 134217728  | <-- alter_table索引日志大小参数
    +----------------------------------+------------+
    12 rows in set (0.00 sec)

所以建议把这个值调大点：

    (root@localhost) [test]> set global innodb_online_alter_log_max_size=512*1024*1024;
    Query OK, 0 rows affected (0.00 sec)

加入my.cnf，根据服务器配置调整：

    # innodb
    innodb_buffer_pool_size = 1G
    innodb_log_file_size = 128M
    innodb_online_alter_log_max_size = 256M # 配置好可以调大至1G

### 在线索引添加遇到的问题--主从延时

比如在主库上的 orders 表上执行了 DDL 操作，比如添加索引用了 5 分钟，那么在从库上面也会去执行这样一个 DDL 操作也需要 5 分钟这样的一个时间，那么就会产生一个5分钟的延时（等 master 上的执行完了后，slave 才开始那个操作）

所以真正在线上会很少直接用 alter table add indexl，alter table add column 这样的方式去执行DDL操作的，即使在 5.7 本版中越来越多的操作对读写都是不阻塞的，但是存在的最大的一个问题就是延时

#### 使用 Percona Toolkit 工具包解决这个问题

[Percona Toolkit Documentation](https://www.percona.com/doc/percona-toolkit/LATEST/index.html)

里面除了 pt-online-schema-change 其他的用处不大

下载

    wget https://github.com/percona/percona-toolkit/archive/refs/tags/v3.3.1.tar.gz

加入环境变量

    $ vim ~/.zshrc

    PATH=~/dl/percona-toolkit-3.3.1/bin:$PATH:$HOME/bin

    $ zsh

#### pt-online-schema-change

这个工具可以在线的用来创建索引或者是DDL，好处是延时非常小，这个工具并不是直接去创建的，而是通过触发器的机制去慢慢的加，有很多参数可以用来控制延时

使用方法：(--alter: alter table "需要执行的操作" D=数据库名 t=表名)

创建示例表：

    (root@localhost) [test]> CREATE TABLE `a` (
      `z` int(11) NOT NULL,
      `a` varchar(512) DEFAULT NULL,
      PRIMARY KEY (`z`)
    ) ENGINE=InnoDB;
    (root@localhost) [test]> insert into a values(1, "aaa");
    (root@localhost) [test]> insert into a values(2, "bbb");
    (root@localhost) [test]> insert into a values(3, "ccc");

修改字符集示例：

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a
    Operation, tries, wait: <--这里只是显示了步骤
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Exiting without altering `test`.`a` because neither --dry-run nor --execute was specified.  Please read the tool's documentation carefully before using this tool.

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a --execute  # 真正执行需要加上--execute參數
    No slaves found.  See --recursion-method if host iZbp16g9pt4wd4rs0iwqrfZ has slaves.
    Not checking slave lag because no slaves were found and --check-slave-lag was not specified.
    Operation, tries, wait:
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Altering `test`.`a`...
    Creating new table...
    Created new table test._a_new OK.
    Altering new table...
    Altered `test`.`_a_new` OK.
    2022-01-15T13:26:19 Creating triggers...
    2022-01-15T13:26:19 Created triggers OK.
    2022-01-15T13:26:19 Copying approximately 1 rows...
    2022-01-15T13:26:19 Copied rows OK.
    2022-01-15T13:26:19 Analyzing new table...
    2022-01-15T13:26:19 Swapping tables...
    2022-01-15T13:26:19 Swapped original and new tables OK.
    2022-01-15T13:26:19 Dropping old table...
    2022-01-15T13:26:19 Dropped old table `test`.`_a_old` OK.
    2022-01-15T13:26:19 Dropping triggers...
    2022-01-15T13:26:19 Dropped triggers OK.
    Successfully altered `test`.`a`.     <--执行成功的提示

创建索引示例：

    $ pt-online-schema-change --alter "add index idx_a(a)" D=test,t=a --execute
    No slaves found.  See --recursion-method if host iZbp16g9pt4wd4rs0iwqrfZ has slaves.
    Not checking slave lag because no slaves were found and --check-slave-lag was not specified.
    Operation, tries, wait:
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Altering `test`.`a`...
    Creating new table...
    Created new table test._a_new OK.
    Altering new table...
    Altered `test`.`_a_new` OK.
    2022-01-15T13:33:34 Creating triggers...
    2022-01-15T13:33:34 Created triggers OK.
    2022-01-15T13:33:34 Copying approximately 1 rows...
    2022-01-15T13:33:34 Copied rows OK.
    2022-01-15T13:33:34 Analyzing new table...
    2022-01-15T13:33:34 Swapping tables...
    2022-01-15T13:33:34 Swapped original and new tables OK.
    2022-01-15T13:33:34 Dropping old table...
    2022-01-15T13:33:34 Dropped old table `test`.`_a_old` OK.
    2022-01-15T13:33:34 Dropping triggers...
    2022-01-15T13:33:34 Dropped triggers OK.
    Successfully altered `test`.`a`.

查看修改后的情况：

    (root@localhost) [test]> show create table a\G
    *************************** 1. row ***************************
          Table: a
    Create Table: CREATE TABLE `a` (
      `z` int(11) NOT NULL,
      `a` varchar(512) DEFAULT NULL,
      PRIMARY KEY (`z`),
      KEY `idx_a` (`a`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    1 row in set (0.00 sec)

这个工具在线上数据量大的情况下，创建索引不是一下子创建完的是慢慢创建的

注意这里在 my.cnf 中配置了用户名密码，所以使用这个工具没有带上用户名密码，如果没有配置用户名密码，需要在工具的参数里带上

查看工具的各项参数：

    $ pt-online-schema-change --help

##### 实现原理

这个工具还是非常有技术含量的

简单来说的话会根据原表（比如 s 表）先创建一张 _tmp_s 的临时表，接着会去原表上创建 insert、update、delete 的触发器，此时如果在执行过程中新产生的数据就会触发过去，这些通过触发器触发过去的是增量数据

但是老的数据则需要把全量数据先给拉过去，全量数据拉过去的时候是通过 insert _tmp_s select from s limit 1000(limit默认1000行，可调) 一批一批过去的

那么可以注意到一个问题，怎么保证全量数据先过去还是增量数据先过去，比如说有 150 万行的原数据还没同步过去增量数据就先过去了，所以这个工具里还有很多细节可以探讨

看实现原理：

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a --dry-run # dry-run 表示只运行不实际导数据
    Operation, tries, wait:
      analyze_table, 10, 1
      copy_rows, 10, 0.25
      create_triggers, 10, 1
      drop_triggers, 10, 1
      swap_tables, 10, 1
      update_foreign_keys, 10, 1
    Starting a dry run.  `test`.`a` will not be altered.  Specify --execute instead of --dry-run to alter the table.
    Creating new table...
    Created new table test._a_new OK.                 <--创建了临时表
    Altering new table...
    Altered `test`.`_a_new` OK.
    Not creating triggers because this is a dry run.  <--创建触发器
    Not copying rows because this is a dry run.       <--拷贝数据
    Not swapping tables because this is a dry run.    <--重命名
    Not dropping old table because this is a dry run. <--删除原来的表
    Not dropping triggers because this is a dry run.  <--删除触发器
    2022-01-15T14:04:39 Dropping new table...
    2022-01-15T14:04:39 Dropped new table OK.
    Dry run complete.  `test`.`a` was not altered.

通过 general_log 查看执行过程：

    (root@localhost) [(none)]> set global log_output = 'table'; -- 日志存到表里
    Query OK, 0 rows affected (0.00 sec)

    (root@localhost) [(none)]> use mysql;
    Database changed
    (root@localhost) [mysql]> truncate table general_log; -- 清一下日志的旧数据
    Query OK, 0 rows affected (0.01 sec)

    (root@localhost) [mysql]> set global general_log = 1; -- 打开general_log
    Query OK, 0 rows affected (0.01 sec)

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=test,t=a --execut # 执行工具命令

    (root@localhost) [mysql]> set global general_log = 0; -- 关闭general_log
    Query OK, 0 rows affected (0.00 sec)

    (root@localhost) [mysql]> select * from general_log limit 3;
    +----------------------------+---------------------------+-----------+-----------+--------------+-------------------------------------------------+
    | event_time                 | user_host                 | thread_id | server_id | command_type | argument                                        |
    +----------------------------+---------------------------+-----------+-----------+--------------+-------------------------------------------------+
    | 2022-05-23 11:25:34.168603 | root[root] @ localhost [] |        17 |         1 | Quit         |                                                 |
    | 2022-05-23 11:25:39.074778 | [root] @ localhost []     |        18 |         1 | Connect      | root@localhost on test using Socket             |
    | 2022-05-23 11:25:39.075121 | root[root] @ localhost [] |        18 |         1 | Query        | SHOW VARIABLES LIKE 'innodb\_lock_wait_timeout' |
    +----------------------------+---------------------------+-----------+-----------+--------------+-------------------------------------------------+
    3 rows in set (0.00 sec)

    (root@localhost) [mysql]> select argument from general_log where thread_id = 18\G
    *************************** 1. row ***************************
    argument: root@localhost on test using Socket
    *************************** 2. row ***************************
    argument: SHOW VARIABLES LIKE 'innodb\_lock_wait_timeout'
    *************************** 3. row ***************************
    argument: SET SESSION innodb_lock_wait_timeout=1
    *************************** 4. row ***************************
    argument: SHOW VARIABLES LIKE 'lock\_wait_timeout'
    *************************** 5. row ***************************
    argument: SET SESSION lock_wait_timeout=60
    *************************** 6. row ***************************
    argument: SHOW VARIABLES LIKE 'wait\_timeout'
    *************************** 7. row ***************************
    argument: SET SESSION wait_timeout=10000
    *************************** 8. row ***************************
    argument: SELECT @@SQL_MODE
    *************************** 9. row ***************************
    argument: SET @@SQL_QUOTE_SHOW_CREATE = 1/*!40101, @@SQL_MODE='NO_AUTO_VALUE_ON_ZERO,ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'*/
    *************************** 10. row ***************************
    argument: SELECT VERSION()
    *************************** 11. row ***************************
    argument: SHOW VARIABLES LIKE 'character_set_server'
    *************************** 12. row ***************************
    argument: SELECT @@server_id /*!50038 , @@hostname*/
    *************************** 13. row ***************************
    argument: SHOW VARIABLES LIKE 'wsrep_on'
    *************************** 14. row ***************************
    argument: SHOW VARIABLES LIKE 'version%'
    *************************** 15. row ***************************
    argument: SHOW ENGINES
    *************************** 16. row ***************************
    argument: SHOW VARIABLES LIKE 'innodb_version'
    *************************** 17. row ***************************
    argument: SHOW VARIABLES LIKE 'innodb_stats_persistent'
    *************************** 18. row ***************************
    argument: SELECT @@SERVER_ID
    *************************** 19. row ***************************
    argument: SHOW GRANTS FOR CURRENT_USER()
    *************************** 20. row ***************************
    argument: SHOW FULL PROCESSLIST
    *************************** 21. row ***************************
    argument: SHOW SLAVE HOSTS
    *************************** 22. row ***************************
    argument: SHOW GLOBAL STATUS LIKE 'Threads_running'
    *************************** 23. row ***************************
    argument: SHOW GLOBAL STATUS LIKE 'Threads_running'
    *************************** 24. row ***************************
    argument: SELECT CONCAT(@@hostname, @@port)
    *************************** 25. row ***************************
    argument: SHOW TABLES FROM `test` LIKE 'a'
    *************************** 26. row ***************************
    argument: SELECT VERSION()
    *************************** 27. row ***************************
    argument: SHOW TRIGGERS FROM `test` LIKE 'a'
    *************************** 28. row ***************************   <--到这里为止是获取表对应的一些信息
    argument: /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */
    *************************** 29. row ***************************
    argument: USE `test`
    *************************** 30. row ***************************   <--看表结构
    argument: SHOW CREATE TABLE `test`.`a`
    *************************** 31. row ***************************
    argument: /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */
    *************************** 32. row ***************************   <--explain表
    argument: EXPLAIN SELECT * FROM `test`.`a` WHERE 1=1
    *************************** 33. row ***************************   <--获取每个列上面的column列信息
    argument: SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema='test' AND referenced_table_name='a'
    *************************** 34. row ***************************
    argument: SHOW VARIABLES LIKE 'version%'
    *************************** 35. row ***************************
    argument: SHOW ENGINES
    *************************** 36. row ***************************
    argument: SHOW VARIABLES LIKE 'innodb_version'
    *************************** 37. row ***************************
    argument: SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema='test' AND referenced_table_name='a'
    *************************** 38. row ***************************
    argument: SHOW VARIABLES LIKE 'wsrep_on'
    *************************** 39. row ***************************
    argument: /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */
    *************************** 40. row ***************************
    argument: USE `test`
    *************************** 41. row ***************************
    argument: SHOW CREATE TABLE `test`.`a`
    *************************** 42. row ***************************
    argument: /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */
    *************************** 43. row ***************************   <--创建新的表 _a_new
    argument: CREATE TABLE `test`.`_a_new` (
      `z` int(11) NOT NULL,
      `a` varchar(512) DEFAULT NULL,
      PRIMARY KEY (`z`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    *************************** 44. row ***************************   <--执行ALTER TABLE操作，因为这张新表是空的，所以ALTER TABLE操作几乎瞬间完成
    argument: ALTER TABLE `test`.`_a_new` CONVERT TO CHARACTER SET utf8mb4
    *************************** 45. row ***************************
    argument: /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */
    *************************** 46. row ***************************
    argument: USE `test`
    *************************** 47. row ***************************
    argument: SHOW CREATE TABLE `test`.`_a_new`
    *************************** 48. row ***************************
    argument: /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */
    *************************** 49. row ***************************
    argument: SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'DELETE'    AND ACTION_TIMING = 'AFTER'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'
    *************************** 50. row ***************************
    argument: SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'UPDATE'    AND ACTION_TIMING = 'AFTER'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'
    *************************** 51. row ***************************
    argument: SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'INSERT'    AND ACTION_TIMING = 'AFTER'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'
    *************************** 52. row ***************************
    argument: SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'DELETE'    AND ACTION_TIMING = 'BEFORE'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'
    *************************** 53. row ***************************
    argument: SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'UPDATE'    AND ACTION_TIMING = 'BEFORE'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'
    *************************** 54. row ***************************
    argument: SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE,        CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING   FROM INFORMATION_SCHEMA.TRIGGERS  WHERE EVENT_MANIPULATION = 'INSERT'    AND ACTION_TIMING = 'BEFORE'    AND TRIGGER_SCHEMA = 'test'    AND EVENT_OBJECT_TABLE = 'a'
    *************************** 55. row ***************************   <--创建了DELETE触发器，IGNORE表示忽略错误，这里加上是为了如果有外键关联会删除失败，所以要加上IGNORE；<=>可以判断NULL值和非NULL值(参考后面的TIPS)
    argument: CREATE TRIGGER `pt_osc_test_a_del` AFTER DELETE ON `test`.`a` FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR 1146 begin end; DELETE IGNORE FROM `test`.`_a_new` WHERE `test`.`_a_new`.`z` <=> OLD.`z`; END
    *************************** 56. row ***************************   <--创建了REPLACE机制的UPDATE触发器，REPLACE机制可以避免全量数据后执行，增量数据先执行的问题
    argument: CREATE TRIGGER `pt_osc_test_a_upd` AFTER UPDATE ON `test`.`a` FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR 1146 begin end; DELETE IGNORE FROM `test`.`_a_new` WHERE !(OLD.`z` <=> NEW.`z`) AND `test`.`_a_new`.`z` <=> OLD.`z`; REPLACE INTO `test`.`_a_new` (`z`, `a`) VALUES (NEW.`z`, NEW.`a`); END
    *************************** 57. row ***************************   <--创建了REPLACE机制的INSERT触发器，REPLACE机制可以避免全量数据后执行，增量数据先执行的问题
    argument: CREATE TRIGGER `pt_osc_test_a_ins` AFTER INSERT ON `test`.`a` FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR 1146 begin end; REPLACE INTO `test`.`_a_new` (`z`, `a`) VALUES (NEW.`z`, NEW.`a`);END
    *************************** 58. row ***************************
    argument: EXPLAIN SELECT * FROM `test`.`a` WHERE 1=1
    *************************** 59. row ***************************
    argument: EXPLAIN SELECT `z`, `a` FROM `test`.`a` LOCK IN SHARE MODE /*explain pt-online-schema-change 3366 copy table*/
    *************************** 60. row ***************************   <--全量导入，LOCK IN SHARE MODE表示锁定的读；LOW_PRIORITY表示没有其他读取的时候才执行这个操作就是降低优先级；因为如果增量数据先执行再执行旧数据就重复了会报出错信息，所以要用IGNORE来忽略执行顺序不同而导致的一些出错信息
    argument: INSERT LOW_PRIORITY IGNORE INTO `test`.`_a_new` (`z`, `a`) SELECT `z`, `a` FROM `test`.`a` LOCK IN SHARE MODE /*pt-online-schema-change 3366 copy table*/
    *************************** 61. row ***************************
    argument: SHOW WARNINGS
    *************************** 62. row ***************************
    argument: SELECT @@SERVER_ID
    *************************** 63. row ***************************
    argument: SHOW GRANTS FOR CURRENT_USER()
    *************************** 64. row ***************************
    argument: SHOW FULL PROCESSLIST
    *************************** 65. row ***************************
    argument: SHOW SLAVE HOSTS
    *************************** 66. row ***************************
    argument: SHOW GLOBAL STATUS LIKE 'Threads_running'
    *************************** 67. row ***************************
    argument: ANALYZE TABLE `test`.`_a_new` /* pt-online-schema-change */
    *************************** 68. row ***************************
    argument: RENAME TABLE `test`.`a` TO `test`.`_a_old`, `test`.`_a_new` TO `test`.`a`
    *************************** 69. row ***************************
    argument: DROP TABLE IF EXISTS `test`.`_a_old`
    *************************** 70. row ***************************
    argument: DROP TRIGGER IF EXISTS `test`.`pt_osc_test_a_del`
    *************************** 71. row ***************************
    argument: DROP TRIGGER IF EXISTS `test`.`pt_osc_test_a_upd`
    *************************** 72. row ***************************
    argument: DROP TRIGGER IF EXISTS `test`.`pt_osc_test_a_ins`
    *************************** 73. row ***************************
    argument: SHOW TABLES FROM `test` LIKE '\_a\_new'
    *************************** 74. row ***************************
    argument:
    74 rows in set (0.00 sec)

用了 replace 机制（命令）就能避免全量数据**后执行**增量数据**先执行**的问题，比如说这时候 update 一条以前的旧数据但是全量的还没进来，那就无法 update，但是没有关系这里直接用 replace 把最后的数据先插进去就行了，replace 如果遇到了有旧数据就会把老数据删除，重新插入新的数据

这个工具有一个限制，就是每张表一定要有主键

这个工具延时不大的原因是相较于普通的做法是 alter 执行完了才会去从库去执行，而这个工具则把操作拆成了很多的小的操作去执行，每一个拆出来的操作都会同步到从机上去，这就是他的优点主从延时会非常小，缺点是执行时间会变很长

对 dbt3 表执行了这个命令发现 time_statistics 表没有主键所以工具执行失败，为该表添加主键解决问题：

    (root@localhost) [dbt3]> alter table time_statistics add column time_id int not null auto_increment primary key first;
    Query OK, 0 rows affected (0.07 sec)

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=dbt3,t=time_statistics --execute

对 employees 库的 employees 表也执行失败，提示有外键关联，这个时候要加上参数--alter-foreign-keys-metho=rebuild_constraints，没有外键关联的不要加这个参数不然也会报错

    ......
    ......
    You did not specify --alter-foreign-keys-method, but there are foreign keys that reference the table. Please read the tool's documentation carefully.

    $ pt-online-schema-change --alter "CONVERT TO CHARACTER SET utf8mb4" D=employees,t=employees --alter-foreign-keys-method=rebuild_constraints --execute

这个工具也蛮有意思的，后面可以研究下 https://github.com/github/gh-ost

### TIPS：<=> 可以判断 NULL 值和非 NULL 值，不用写 is null

MySQL 独有的语法，既可以统计 NULL 值，也可以去计算非 NULL 值

    (root@localhost) [test]> select * from z;
    +------+
    | b    |
    +------+
    | NULL |
    |    1 |
    |    2 |
    |    3 |
    +------+
    4 rows in set (0.01 sec)

    (root@localhost) [test]> select * from z where b = NULL;
    Empty set (0.00 sec)

    (root@localhost) [test]> select * from z where b <=> NULL;
    +------+
    | b    |
    +------+
    | NULL |
    +------+
    1 rows in set (0.01 sec)

    (root@localhost) [test]> select * from z where b <=> 1;
    +------+
    | b    |
    +------+
    | 1    |
    +------+
    1 rows in set (0.01 sec)

## 索引组织表

* 简写 IOT 
* 对于主键的索引
  * 叶子节点存放了这一整行所有的数据
* 其他索引
  * 叶子节点只是存放了索引的键值和主键值
* 回表
* 16K 每页
* 高扇出

假设一张表有 a、b、c、d 四个列，a 为主键

| PK  |     |     |     |
| --- | --- | --- | --- |
| a   | b   | c   | d   |
| ... | ... | ... | ... |
| ... | ... | ... | ... |
| ... | ... | ... | ... |

对于主键的这棵索引对应的叶子节点存放的是一整行记录，包含所有的列 "|a|b|c|d|"

对于二级索引(普通索引、唯一索引)来说的话，叶子节点存放的是索引的列以及主键的列 "|b|a|"（这里 b 是索引的列）

对于非叶节点不管是主键还是二级索引，存放的都是键值和指针 "|KEY|Point|"，指针的大小在 MySQL 中固定的是 6 字节，键值大小根据数据类型来，非叶节点不存数据

如果表没有加主键，MySQL 会自动帮你创建一个主键，但是对用户来说是不可见的

这就是索引组织表

### 通过一个计算模型来理解索引组织表

假设有张表主键值是 A 是 8 个字节的 bigint，每条记录大小是 300 字节，每个页大小默认是 16K

#### 问题1：如果说这张表 B+ 树的高度为 1，能存放多少条记录？

高度为 1 表示 root 页就是叶子页

每页存放数/每条记录大小 = (16*1024)/300 ≈ 50 条

#### 问题2：如果说这张表 B+ 树的高度为 2，能存放多少条记录？

高度为 2 的时候

此时高度为 1 的非叶节点存放的是索引列和指针，现在索引的列是 8 个字节指针是 6 个字节，所以每一条记录是 14 个字节

(16*1024)/(8+6) ≈ 1000  也就是扇出了 1000 个叶子节点，那么答案就是 1000\*50 ≈ 50000 条记录

#### 问题3：如果说这张表 B+ 树的高度为 3，能存放多少条记录？

根据问题 2 的原理，每个非叶节点扇出的都是 1000 个指针，那么就是 1000\*1000\*50 ≈ 5000 万条记录

如果是 4 层就再乘以 1000 ≈ 500 亿条记录

B+ 树在实际的生产过程当中不会很高，一般最高 4，5 层就差不多了

#### 意义

B+ 树的总体高度不高意味着根据索引的查询次数不多，表变大了数据变大了查询速度不会几何级的上升，哪怕 4 层 500 亿数据了也还是只要查询 4 次就行了

最差的 HDD 盘每秒能做 100 次 IO 找 3 次 = 3*(1/100) = 0.03 秒，找 4 次也就 4*(1/100) = 0.04 秒，如果存储介质改用 SSD 会更快(至少提升 100 倍)

像根节点基本就是在内存里的还可以省一部分 IO，如果你内存够大的话全放在 buff_size 里都可以

B+ 树的好处是查询非常快，不过这里指的查询是查 1 条记录或某几条记录，如果是要根据时间的索引查询某个时间范围内或者根据主键来查都很快

不过要是查几千万的数据并且还有 join 的那还是会慢的

### 回表概念 重要！

如果查询的条件是主键，那么只要一次就可以把数据查询完毕，因为主键包含了一列的所有数据

但是如果查询条件不是主键索引而是其他(二级)索引，那么会先从叶子节点先查询出其他索引对应的主键索引，然后再用主键索引查询一次，这就是回表

举个例子，下面的表中 a 是主键，b 是二级索引

    | PK  | KEY |     |     |
    | --- | --- | --- | --- |
    | a   | b   | c   | d   |
    | ... | ... | ... | ... |
    | ... | ... | ... | ... |
    | ... | ... | ... | ... |

根据主键所有查询的时候只要一次

    select where a = ?

根据二级索引查询要两次，即书签查找，也叫做回表

    select a where b = ?   -- 先根据二级索引b找到主键索引a
    select c,d where a = ? -- 在通过主键索引a找到其他数据

所以主键查询要比二级索引查询速度快

## 堆表 -- MyISAM

* 所有的数据存放在一个堆文件里面
* 索引存在各自的索引文件里面
* 无序数据的集合叫做堆
* 堆表中主键索引或者二级索引中存放了指向堆表具体数据一个指针
* 堆表的索引是有序的，但是是数据是无序的，而索引组织表则索引和数据都是有序的

## 组织索引表和堆表的优缺点

### 因为插入是不用考虑排序所以堆表的插入速度比较快

其实这个观点是不对的，虽然说数据插入到堆是无序数据组合速度很快等等这都是对的，问题是表上会没有任何索引的吗(有索引会有维护索引的代价)，除非建的表是没有索引的也就是所有的数据是存放在堆中的那么 insert 速度的确是很快的，所以说除非全部是堆表没有索引，那么这个条件或许成立

第二点 MySQL 每张表最好一定要有一个主键，一旦有主键了一定会对应一个索引，一旦有索引插入速度都是差不多的都会慢

### MyISAM (堆表) InnoDB (索引组织表)，哪种引擎更好

MyISAM 适合读？InnoDB 适合写？这个观点对现在的版本来说已然是错误的，从 5.7 开始任何场景下都是 InnoDB 快，MyISAM 跑多核肯定是跑不满的

索引组织表中的回表规则，导致 PK 查询要比二级索引查询要快，在堆表中并没有这个问题，因为堆表的叶子节点存放的是指针不需要额外的一次查询，所以堆表是没有回表的或者认为它的回表就是去查询堆表，堆表中 PK 查询和二级索引查询的速度在同规模下速度基本是一致的

堆表的缺点是：

连续性不是很好，做主键的范围查询的时候速度没有索引组织表快，但是主键的范围查询通常来说也用得并不多

在做 DML 操作的时候维护索引代价大，所有的索引都需要修改，比如主键为 1 的这条记录现在这条记录占用 100 个字节，这时候如果发生了更新变成 300 个字节了，首先堆表不能原地更新，如果不能在同一个位置更新就会在堆表中新找一块空间用来更新数据，然后再去更新主键 1。这时候会发现主键值为 1 的这条记录位置发生了更新，但是索引的叶子节点又都指向的是老的物理地址，所以这时候就都需要更新

在索引组织表中，如果主键的值不更改的话，对于非索引列的更新不需要修改其他的索引，因为二级索引里存放的是一个主键值，只要主键值不变化二级索引就不需要更新

#### 填充因子 5.7 开始

一个页插满的时候，会留出一部分空间留给这个页中的其他记录进行更新，这个叫填充因子

MySQL 的填充因子默认是一个页大小的 1/16(1K)

    (root@localhost) [(none)]> show variables like 'innodb%fill%';
    +--------------------+-------+
    | Variable_name      | Value |
    +--------------------+-------+
    | innodb_fill_factor | 100   |
    +--------------------+-------+
    1 row in set (0.00 sec)

线上一般不会调这个参数，如果更新操作多的话可以试着调一下